---
title: "ex5"
format: html
editor: visual
---

# Challenge 1: Sampling Movies

For this first challenge we will be conducting statistics on the run-time of minutes for movies made between 1920 to 1979

### Step 1: Load in Libraries and Data

For this challenge, we will be using functions from the {tidyverse} and {mosaic} packages, so we will load them in now along with the IMDB-movies dataset

```{r}
#| message: false
#| warning: false
library(tidyverse)
library(mosaic)

f <- "https://raw.githubusercontent.com/difiore/ada-datasets/main/IMDB-movies.csv"

d <- read_csv(f)
names(d)
```

### Step 2: Filter Movies Based on Length and Release Year

Next we need to narrow down our list of movies. We will do this by calling the filter function to select movies with startYear values of 1920-1979 and then filter based on runtimeMinutes for movies which are 60 to 180 minutes (1 to 3 hours). After that, we want to assign a decade designation to each movie. We will be this by using the case_when() function within the mutate() function. The case_when() function will assign movies a specific decade designation based on when they were released. As a result, we get a dataset (d2) with 5,651 movies

```{r}
#| message: false
#| warning: false
d2 <- d |>
  filter(startYear >= 1920 & startYear <= 1979) |>
  filter(runtimeMinutes >= 60 & runtimeMinutes <= 180) |>
  mutate(decade = case_when(
    startYear >= 1920 & startYear <= 1929 ~ "20s",
    startYear >= 1930 & startYear <= 1939 ~ "30s",
    startYear >= 1940 & startYear <= 1949 ~ "40s",
    startYear >= 1950 & startYear <= 1959 ~ "50s",
    startYear >= 1960 & startYear <= 1969 ~ "60s",
    startYear >= 1970 & startYear <= 1979 ~ "70s"
  ))  
```

### Step 3: Plot Histograms

Now we will do some initial visualization of our data. We will use ggplot() to create histograms which, using facet_wrap(), will show the distribution of runtimeMinutes for each decade.

```{r}
#| message: false
#| warning: false
ggplot(data = d2, mapping = aes(x = runtimeMinutes)) +
  geom_histogram() +
  facet_wrap(vars(decade))
```

### Step 4: Calculate Population Mean and Standard Deviation

For later comparison, we will measure the mean and standard deviation for runtimeMinutes per decade and save it in a data frame called "results". This will utilize the group_by() and summarise() functions to group observations based on matching decade values before summarizing the mean and standard deviations for runtimeMinutes

```{r}
#| message: false
#| warning: false
results <- d2 |>
  group_by(decade) |>
  summarise(popMean = mean(runtimeMinutes), popSD = sd(runtimeMinutes))
```

### Step 5: Sample of 100 Movies

Next, we will take a sample of 100 movies from each decade and calculate the mean and standard deviation of runtimeMinutes for each decade's sample of 100 movies. Rather than rewrite the same code for each decade, I created a function which will take our d2 data set, the value of the decade to sample from, and the variable we want to measure (runtimeMinutes). The final argument is the number of samples we want to pull from the data set based on the other arguments.

```{r}
#| message: false
#| warning: false
movieSamp <- function(df, decadeVal, variable, num){
  data <- filter(df, decade == decadeVal)
  samp <- slice_sample(data, n = num)
  sampMean <- mean(samp[[variable]])
  sampSD <- sd(samp[[variable]])
  data <- data.frame(runTimeMean = sampMean, runTimeSD = sampSD)
  return(data)
}

d20s <- movieSamp(d2, "20s", "runtimeMinutes", 100)
d30s <- movieSamp(d2, "30s", "runtimeMinutes", 100)
d40s <- movieSamp(d2, "40s", "runtimeMinutes", 100)
d50s <- movieSamp(d2, "50s", "runtimeMinutes", 100)
d60s <- movieSamp(d2, "60s", "runtimeMinutes", 100)
d70s <- movieSamp(d2, "70s", "runtimeMinutes", 100)

```

### Step 6: Calculate the Standard Error Based on Sample Population Mean

Next we need to calculate the standard error of the population's mean runtimeMinutes based on the standard deviation from our sample of 100 movies. To do this, I created another function which takes the data set we want and the standard deviation variable in the data set to calculate the standard error. I then use the mutate() function to add a third column (runTimeSE) to each decades data frame holding these metrics

```{r}
#| message: false
#| warning: false
se <- function(df, sdVariable, sampNum){
  sd <- df[[sdVariable]]
  se <- sd/sqrt(sampNum)
  return(se)
}
d20s <- d20s |>
  mutate(runTimeSE = se(d20s, "runTimeSD", 100))
d30s <- d30s |>
  mutate(runTimeSE = se(d30s, "runTimeSD", 100))
d40s <- d40s |>
  mutate(runTimeSE = se(d40s, "runTimeSD", 100))
d50s <- d50s |>
  mutate(runTimeSE = se(d50s, "runTimeSD", 100))
d60s <- d60s |>
  mutate(runTimeSE = se(d60s, "runTimeSD", 100))
d70s <- d70s |>
  mutate(runTimeSE = se(d70s, "runTimeSD", 100))

```

### Step 7: Compare Estimates of Population runtimeMinutes with the Sample of 100

Below is a table listing the population and sample measurements of mean and standard deviation along with the sample standard error we calculated in step 6 . The means and standard deviation of the population are fairly similar, with some variation in each decade. The standard error is low for each decade, indicating they are good estimates of the population. I used the following to calculate the population standard error: sd/sqrt(100)

```{r}
#| message: false
#| warning: false
d20se <- 26.20133/sqrt(100)
d30se <- 17.28879/sqrt(100)
d40se <- 19.12372/sqrt(100)
d50se <- 19.20646/sqrt(100)
d60se <- 21.23202/sqrt(100)
d70se <- 17.95934/sqrt(100)
```

| Decade | PopMean | SampleMean | PopSD | SampleSD | PopSE | SampleSE |
|--------|---------|------------|-------|----------|-------|----------|
| 20s    | 96.3    | 96.9       | 26.2  | 26.1     | 2.62  | 2.61     |
| 30s    | 90.3    | 91.8       | 17.3  | 16.6     | 1.72  | 1.66     |
| 40s    | 97.3    | 97.8       | 19.1  | 20.1     | 1.91  | 2.01     |
| 50s    | 98.9    | 98.8       | 19.2  | 18.9     | 1.92  | 1.89     |
| 60s    | 105.6   | 105        | 21.2  | 19.3     | 2.12  | 1.93     |
| 70s    | 103.8   | 105        | 18.0  | 18.1     | 1.79  | 1.81     |

### Step 8: Create Sampling Distribution

Now, we shall create a sampling distribution based on runtimeMinutes which will pull 1000 random samples of 100 movies from each decade without replacement. From this sample distribution we will calculate the mean and standard deviation for each sample pulled. To do this I created a function which takes the data set (d2), variable (runtimeMinutes), decade (20s, 30s, etc), sample repetitions (1000), and the number of movies to be pulled with each sample (100). I use a for() loop in this function to do each iteration of the sampling distribution. Originally, I tried using the do() function from {mosaic} but this resulted in each sample in the distribution having the same mean and standard deviation, which did not seem right haha.

```{r}
#| message: false
#| warning: false
sampMetricsDecade <- function(df, variable, decadeVal, sampReps, sampNum){
  data <- filter(df, decade == decadeVal)
  sampDistMean <- as.numeric(sampReps)
  sampDistSD <- as.numeric(sampReps)
  for(i in 1:sampReps){
    sample <- slice_sample(data, n = sampNum)
    sampDistMean[i] <- mean(sample[[variable]])
    sampDistSD[i] <- sd(sample[[variable]])
  }
  print(paste("Mean and standard deviation for", sampReps, "random samples of", sampNum, "survivors is in dataframe!"))
  return(data.frame(means = sampDistMean, standard_deviation = sampDistSD))
}
d20samp <- sampMetricsDecade(d2, "runtimeMinutes", "20s", 1000, 100)
d30samp <- sampMetricsDecade(d2, "runtimeMinutes", "30s", 1000, 100)
d40samp <- sampMetricsDecade(d2, "runtimeMinutes", "40s", 1000, 100)
d50samp <- sampMetricsDecade(d2, "runtimeMinutes", "50s", 1000, 100)
d60samp <- sampMetricsDecade(d2, "runtimeMinutes", "60s", 1000, 100)
d70samp <- sampMetricsDecade(d2, "runtimeMinutes", "70s", 1000, 100)

```

### Step 9: Calculate Mean and Standard Deviation of the Sampling Distribution and Plot Sampling Distribution

Finally in our analysis, we will calculate the mean and standard deviation of the sampling distribution we generated. I will do this by passing the mean variable though a function I made to calculate the mean and standard deviation of the sampling distributions. The standard deivation of the sample distribution means gives us our standard error for the sampling distribution. Then, to visualize our data, we will plot histograms of the distribution of the means in the sampling distribution. These all have a shape associated with a normal distribution.

```{r}
#| message: false
#| warning: false
sampMeanSD <- function(df, Meanvariable){
  sampDistMean <- mean(df[[Meanvariable]])
  sampDistSD <- sd(df[[Meanvariable]])
  print(paste("Mean =", sampDistMean, "; SD =", sampDistSD))
  return(data.frame(sampleDistMean = sampDistMean, sampleDistSD = sampDistSD))
}

d20distMeanSD <- sampMeanSD(d20samp, "means")
d30distMeanSD <- sampMeanSD(d30samp, "means")
d40distMeanSD <- sampMeanSD(d40samp, "means")
d50distMeanSD <- sampMeanSD(d50samp, "means")
d60distMeanSD <- sampMeanSD(d60samp, "means")
d70distMeanSD <- sampMeanSD(d70samp, "means")

hist(d20samp$means)
hist(d30samp$means)
hist(d40samp$means)
hist(d50samp$means)
hist(d60samp$means)
hist(d70samp$means)

```

### Step 10: Comparing The Population, Sample, and Sampling Distribution

Below I have the standard error for each decade's sample, population, and sample distribution. The sample distribution standard error is generally lower than the sample standard error (except for the 70s), suggesting that the sample distribution is a more accurate estimate of the population.

| Decade | SampleSE | PopSE | SampleDistSE |
|--------|----------|-------|--------------|
| 20s    | 2.71     | 2.62  | 1.55         |
| 30s    | 1.86     | 1.72  | 1.6          |
| 40s    | 1.76     | 1.91  | 1.76         |
| 50s    | 1.87     | 1.92  | 1.81         |
| 60s    | 2.26     | 2.12  | 2.01         |
| 70s    | 1.72     | 1.79  | 1.79         |

# Challenge 2: Sampling Zombie Survivors

In this next challenge, we will analyze the quantitative measures for a group of zombie apocalypse survivors!

### Step 1: Load in Libraries and Data

We will first load in the libraries we need for this analysis, {tidyverse}, {ggplot2}, and {mosaic}. Next we will load in the zombies.csv data set and name it "z"

```{r}
#| message: false
#| warning: false
library(tidyverse)
library(ggplot2)
library(mosaic)
f <- "https://raw.githubusercontent.com/difiore/ada-datasets/main/zombies.csv"
z <- read_csv(f)
```

### Step 2: Initial Metrics

Now we will calculate the mean and standard deviation of the population for all the quantitative measure in the file (height, weight, age, number of zombies killed, and years of education). We cannot use the sd() function to calculate the standard deviation since we are looking at the whole population here. Instead we will use the equation sqrt((n-1)/n)\*sd(variable) where n is the total length of the variable in the data set, which is 1000 in this case.

```{r}
#| message: false
#| warning: false
n <- 1000
MeanSDz <- z |>
  group_by(gender) |>
  summarise(meanHeight = mean(height), meanWeight = mean(weight), meanAge = mean(age),
            meanZKills = mean(zombies_killed), meanEdYrs = mean(years_of_education),
         sdHeight = sqrt((n - 1)/n)*sd(height), sdWeight = sqrt((n-1)/n)*sd(weight),
         sdAge = sqrt((n-1)/n)*sd(age), sdZKills = sqrt((n-1)/n)*sd(zombies_killed),
         sdEdYrs = sqrt((n-1)/n)*sd(years_of_education))
```

### Step 3: Boxplots by Gender

To visualize each of these variables, we ill use ggplot() to create boxplots of each variable based on gender.

```{r}
#| message: false
#| warning: false
#Height
ggplot(data = z, mapping = aes(x = gender, y = height))+
  geom_boxplot() +
  ggtitle("Height by Gender")
#Weight
ggplot(data = z, mapping = aes(x = gender, y = weight))+
  geom_boxplot() +
  ggtitle("Weight by Gender")
#Age
ggplot(data = z, mapping = aes(x = gender, y = age))+
  geom_boxplot() +
  ggtitle("Age by Gender")
#Number of Zombies killed
ggplot(data = z, mapping = aes(x = gender, y = zombies_killed))+
  geom_boxplot() +
  ggtitle("Zombie Kills by Gender")
#Years of education
ggplot(data = z, mapping = aes(x = gender, y = years_of_education))+
  geom_boxplot() +
  ggtitle("Years of Education by Gender")

```

### Step 4: Scatterplots of Height and Weight by Gender

Now we will again use ggplot() to plot the distribution of height based on age and weight based on age by gender in scatterplots. Based on the plots, height and age seem to have a positive relationship in that as age increases height increases steadily. Weight in relation to age though seems to be a bit more randomly distributed, with some younger individual weighing more than older ones and vice-a-versa.

```{r}
#| message: false
#| warning: false
#Height and age
ggplot(data = z, mapping = aes(x = age, y = height, color = gender)) +
  geom_point() +
  ggtitle("Height in relation to Age")

#Weight and age
ggplot(data = z, mapping = aes(x = age, y = weight, color = gender)) +
  geom_point() +
  ggtitle("Weight in relation to Age")
```

### Step 5: Create Histograms and QQ Plots

We will not use the hist() and qqnorm() functions to create histograms and QQ plots of each variable of interest. Based on these plots, height, weight and age appear to be normally distributed while number of zombie kills and years of education are not.

```{r}
#| message: false
#| warning: false
#Height
hist(z$height) #looks normal
qqnorm(z$height) #normal

#Weight
hist(z$weight) #normal
qqnorm(z$weight) #normal

#Age
hist(z$age) #normal
qqnorm(z$age) #normal

#Zombie Kills
hist(z$zombies_killed) #not normal
qqnorm(z$zombies_killed) #not normal

#Years of Education
hist(z$years_of_education) #not normal
qqnorm(z$years_of_education) #not normal

```

### Step 6: 50 Survivor Sample

Now we will take a sample of 50 survivors and calculate the mean, standard deviation, standard error, and 95% confidence intervals of this sample for each variable. First we will use the slice_sample() function to create a sample data set of 50 survivors. Then we will pass this sample through a function I made which will calculate the values we want from this sample of 50.

```{r}
#| message: false
#| warning: false
sampleSurvivors <- slice_sample(z, n = 50)
metrics <- function(data, variable, lowCIBound, highCIBound){
  sampMean <- mean(data[[variable]])
  sampSD <- sd(data[[variable]])
  sampSE <- sampSD/sqrt(50)
  sampCI <- sampMean + qnorm(c(lowCIBound, highCIBound)) * sampSE
  print(paste(variable, "mean:", sampMean))
  print(paste(variable, "standard deviation:", sampSD))
  print(paste(variable, "standard error:", sampSE))
  print(paste(variable, "lower confidence intervals:", sampCI[1], "upper confience interval:", sampCI[2]))
  return(data.frame(metric = c("mean", "standard deviation", "standard error", "low confidence interval", "high confidence interval"), value = (c(sampMean, sampSD, sampSE, sampCI[1], sampCI[2]))))
}

heightMetrics <- metrics(sampleSurvivors, "height", 0.025, 0.975)
weightMetrics <- metrics(sampleSurvivors, "weight", 0.025, 0.975)
ageMetrics <- metrics(sampleSurvivors, "age", 0.025, 0.975)
zombieKillsMetrics <- metrics(sampleSurvivors, "zombies_killed", 0.025, 0.975)
educationMetrics <- metrics(sampleSurvivors, "years_of_education", 0.025, 0.975)

```

### Step 7: Create a Sampling Distribution

Now we will draw 199 random sample of 50 survivors to create a sampling distribution which with out initial sample will result in a distribution of 200 means. We will then calculate the means and standard deviations of the sampling distribution for each variable.

```{r}
#| message: false
#| warning: false
sampMetrics <- function(df, variable, sampReps, sampNum){
  sampDistMean <- vector()
  sampDistSD <- vector()
  for(i in 1:sampReps){
    sample <- slice_sample(df, n = sampNum)
    sampDistMean[i] <- mean(sample[[variable]])
    sampDistSD[i] <- sd(sample[[variable]])
  }
  print(paste("Mean and standard deviation for", sampReps, "random samples of", sampNum, "survivors is in dataframe!"))
  return(data.frame(means = sampDistMean, standard_deviation = sampDistSD))
}

heightSamp <- sampMetrics(z, "height", 199, 50)
heightSampMMSE <- summarise(heightSamp, MM = mean(means), SE = sd(means))

weightSamp <- sampMetrics(z, "weight", 199, 50)
weightSampMMSE <- summarise(weightSamp, MM = mean(means), SE = sd(means))

ageSamp <- sampMetrics(z, "age", 199, 50) 
ageSampMMSE <- summarise(ageSamp, MM = mean(means), SE = sd(means))

zombieKillsSamp <- sampMetrics(z, "zombies_killed", 199, 50) 
zombieKillSampMMSE <- summarise(zombieKillsSamp, MM = mean(means), SE = sd(means))

educationSamp <- sampMetrics(z, "years_of_education", 199, 50) 
educationSampMMSE <- summarise(educationSamp, MM = mean(means), SE = sd(means))
```

The following mean and standard deviation values are based on the most recent run of this function on 2/27

For all of my variables, compared to the first sample of 50, the standard deviations for the sampling distributions are similar to the standard error calculated for the first sample of 50 with very little variation. The table below summarizes the mean, standard deviation, and standard error for the sample of 50 along with the range of means, mean of the means, standard deviation range, and standard deviation of the means (standard error) of the sample distribution. The values for the sample mean and standard deviation fall within the range in the sampling distribution while the standard error of both the sample and sampling distribution are similar to each other.

| Variable | 50SampMean | 50SampSD | 50SampSE | DistMeanRange | DistMeanMean | DistSDRange | DistSE |
|--------|------------|----------|----------|---------|---------|-----------|-------|
| Height | 67.72 | 4.14 | 0.57 | 66.47-69.11 | 67.6 | 2.65-5.32 | 0.56 |
| Weight | 140.78 | 18.36 | 2.60 | 137.33-150.66 | 144 | 13.4-23.7 | 2.44 |
| Age | 19.25 | 2.54 | 0.36 | 19-21.29 | 20.1 | 2.23-3.87 | 0.39 |
| Zombie Kills | 2.46 | 1.55 | 0.22 | 2.36-3.7 | 3.02 | 1.3-2.25 | 0.26 |
| Years of Education | 2.94 | 1.75 | 0.25 | 2.36-3.96 | 3.03 | 1.33-2.12 | 0.26 |

### Step 8: Plot Sampling Distribution

We will not use the hist() function to plot the sampling distributions for each variable. Based on these histograms, all the variables appear to be fairly normally distributed. Height and weight seem to be weighted towards the right and left respectively but follow a bell curve looking pattern associated with normal distributions. The number of zombie kills and years of education appear now to be normally distributed compared to when we first plotted them.

```{r}
#| message: false
#| warning: false
hist(heightSamp$means) 
qqnorm(heightSamp$means)
#weight
hist(weightSamp$means)
qqnorm(weightSamp$means)
#age
hist(ageSamp$means)
qqnorm(ageSamp$means)
#zombie kills
hist(zombieKillsSamp$means) 
qqnorm(zombieKillsSamp$means)
#years of education
hist(educationSamp$means) 
qqnorm(educationSamp$means)

```

### Step 9: Create Confidence Intervals

Now we will construct 95% confidence intervals around the sampling distributions. I did this by first creating a function which takes the data we are working with (each sampling distribution) and the name of the column we want to analyse (means) as arguments. The confidence intervals of our sampling distribution are similar to those calculated for our single sample of 50 survivors:

Sample Height CI: 66.43, 68.74; Sample Distribution Height CI: 66.5, 68.7\
Sample Weight CI: 136.91, 148.14; Sample Distribution Weight CI: 138, 149\
Sample Age CI: 19.33, 20.98; Sample Distribution Age CI: 19.2, 20.9\
Sample Zombie Kills CI: 2.4, 3.56; Sample Distribution Zombie Kills CI: 2.52, 3.46\
Sample Education Years CI: 2.54, 3.46; Sample Distribution Education Years CI: 2.56, 3.46

The sample confidence intervals appear to be a little bit wider than the confidence intervals for the sample distributions

```{r}
#| message: false
#| warning: false
samp95CI <- function(df, meanVariable){
  m <- mean(df[[meanVariable]])
  se <- sd(df[[meanVariable]])
  ci <- m + qnorm(c(0.025, 0.975)) * se
  print("Confidence intervals have been caluclated and stored in values.")
  return(ci)
}

heightSampCI <- samp95CI(heightSamp, "means")
weightSampCI <- samp95CI(weightSamp, "means")
ageSampCI <- samp95CI(ageSamp, "means")
zombieKillSampCI <- samp95CI(zombieKillsSamp, "means")
edYearsSampCI <- samp95CI(educationSamp, "means")
```

### Step 10: Confidence Intervals by Bootstrapping

Finally, we will again calculate the confidence intervals but by using the bootstrapping method. Using the function I created below, we will sample the mean of each variable 1000 times with replacement from the original sample of 50 survivors. Using this method, we get the following confidence intervals:

Height: 66.37, 68.69\
Weight: 136.74, 148.56\
Age: 19.42, 20.99\
Zombie Kills: 2.4, 3.54\
Education Years: 2.56, 3.46

Compared to step 9, these confidence intervals are overall wider, similar to the original confidence intervals we created for the sample of 50

```{r}
#| message: false
#| warning: false
bootstrap <- function(df, variable, resampNum){
  n_boot <- resampNum
  boot <- vector(length=n_boot)
  n <- length(df[[variable]])
  for(i in 1:n_boot){
    boot[[i]] <- mean(sample(df[[variable]], n, replace = TRUE))
  }
  ci <- quantile(boot, probs = c(0.025, 0.975))
  print(ci)
  return(ci)
}
heightBoot <- bootstrap(sampleSurvivors, "height", 1000)
weightBoot <- bootstrap(sampleSurvivors, "weight", 1000)
ageBoot <- bootstrap(sampleSurvivors, "age", 1000)
zombieKillsBoot <- bootstrap(sampleSurvivors, "zombies_killed", 1000)
edYearsBoot <- bootstrap(sampleSurvivors, "years_of_education", 1000)
```
